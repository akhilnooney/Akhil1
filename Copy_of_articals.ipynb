{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of articals.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilnooney/Akhil1/blob/master/Copy_of_articals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Kepv3KMonY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we import the class that we need scraping our blog\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer\n",
        "\n",
        "\n",
        "# we create a response variable\n",
        "\n",
        "response = requests.get('https://forecast.weather.gov/MapClick.php?textField1=33.22&textField2=-97.15#.XaXfI0ZKjb0')\n",
        "\n",
        "# we initialize beautiful soup and pass in our response\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# we create a variable called posts and we know that our all our blog posts are in a div called blog-entry-content\n",
        "\n",
        "posts = soup.findAll(\"div\",{\"class\": \"tombstone-container\"})\n",
        "# writing to csv file\n",
        "\n",
        "with open('articles.csv', 'w') as csv_file:\n",
        "    csv_writer = writer(csv_file)\n",
        "\n",
        "    # creating headers in the csv file\n",
        "    headers = ['Period', 'Short_Desc', 'Temp','Desc']\n",
        "\n",
        "    # writing a row of headers in the csv\n",
        "    csv_writer.writerow(headers)\n",
        "\n",
        "    # now lets loop through our posts\n",
        "\n",
        "    for post in posts:\n",
        "      period=post.find_all(\"p\",{\"class\": \"period-name\"})[0].get_text()\n",
        "      short_desc=post.find_all(\"p\",{\"class\": \"short-desc\"})[0].get_text()\n",
        "      temp_cell=post.find(\"p\",{\"class\":\"short-desc\"}).next_sibling.get_text()\n",
        "      desc_cell=post.find(\"img\",{\"class\": \"forecast-icon\"}).get('alt','')\n",
        "      csv_writer.writerow([period, short_desc,temp_cell,desc_cell])\n",
        "\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGfytRVJXXoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbsEfgiXYv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}